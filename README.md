# ğŸ§© **Data Loading Stage â€” LLMOps Flipkart Product Recommender System**

This stage establishes the **data ingestion and preparation layer** for the **LLMOps Flipkart Product Recommender System**.
It introduces the foundational modules that load, process, and embed Flipkart product reviews into an **AstraDB vector store**, preparing the data for downstream retrieval and recommendation tasks.

The three new modules created in this stage â€” `config.py`, `data_converter.py`, and `data_ingestion.py` â€” enable the system to connect securely to AstraDB, handle raw CSV review data, and populate the vector database with embedded text representations.


## ğŸ—‚ï¸ **Project Structure (Updated)**

```text
llmops-flipkart-product-recommender/
â”œâ”€â”€ .env
â”œâ”€â”€ .gitignore
â”œâ”€â”€ .python-version
â”œâ”€â”€ data/
â”‚   â””â”€â”€ flipkart_product_review.csv
â”œâ”€â”€ flipkart/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py               # âš™ï¸ Loads env vars + model/DB settings (new)
â”‚   â”œâ”€â”€ data_converter.py       # ğŸ”„ CSV â†’ LangChain Documents (new)
â”‚   â””â”€â”€ data_ingestion.py       # ğŸ§  Embeddings + AstraDB vector store (new)
â”œâ”€â”€ grafana/
â”œâ”€â”€ prometheus/
â”œâ”€â”€ static/
â”œâ”€â”€ templates/
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ custom_exception.py
â”‚   â””â”€â”€ logger.py
â”œâ”€â”€ main.py
â”œâ”€â”€ pyproject.toml
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ setup.py
â”œâ”€â”€ uv.lock
â””â”€â”€ README.md
```


## âš™ï¸ **Overview of the Data Loading Components**

This update introduces the three key modules that together form the **data loading pipeline**:

### 1. `flipkart/config.py`

Defines and loads all environment variables required for connecting to AstraDB and Hugging Face services.
It centralises key configuration settings such as API tokens, model identifiers, and database endpoints, keeping credentials safely stored in the `.env` file.

### 2. `flipkart/data_converter.py`

Handles reading the Flipkart review dataset from CSV format, removing missing entries, and converting each row into a **LangChain `Document`**.
Each document stores the review text as its content and the product title as metadata â€” ideal for embedding and later retrieval.

### 3. `flipkart/data_ingestion.py`

Initialises the **Hugging Face embedding model** and the **AstraDB vector store** using the configuration parameters.
It can either load an existing vector store or ingest new review documents by embedding and uploading them into the AstraDB collection.


## ğŸ§© **Example Usage**

```python
from flipkart.data_ingestion import DataIngestor

# Initialise the ingestion process
ingestor = DataIngestor()

# Option 1: Load existing AstraDB vector store
vstore = ingestor.ingest(load_existing=True)

# Option 2: Ingest new documents into the store
# vstore = ingestor.ingest(load_existing=False)

print("Vector store ready:", vstore)
```

### Example Output

```
Vector store ready: <AstraDBVectorStore(collection_name='flipkart_database')>
```

## âœ… **In Summary**

This stage lays the groundwork for all subsequent LLM-powered components:

* Introduces environment-based configuration through `config.py`.
* Converts raw Flipkart review data into structured `LangChain Document` objects.
* Builds and populates an **AstraDB vector store** using **Hugging Face embeddings**.
* Creates a clean, modular entry point for future retrieval and reasoning stages.

The **data loading stage** is now complete â€” paving the way for the **RAG pipeline and recommendation logic** to follow in the next phase.
