# `flipkart/` README â€” Core Backend Logic

This folder contains the **core backend logic** for the **LLMOps Flipkart Product Recommender System**.
It handles configuration, data processing, ingestion, and the construction of the **Retrieval-Augmented Generation (RAG)** chain â€” forming the foundation of the systemâ€™s intelligent recommendation and reasoning pipeline.



## ğŸ“ Folder Overview

```text
flipkart/
â”œâ”€â”€ __init__.py
â”œâ”€â”€ config.py          # âš™ï¸  Centralised configuration for environment and models
â”œâ”€â”€ data_converter.py  # ğŸ”„  Converts Flipkart CSV reviews into LangChain Documents
â”œâ”€â”€ data_ingestion.py  # ğŸ§   Builds AstraDB vector store and ingests review documents
â””â”€â”€ rag_chain.py       # ğŸ§©  Constructs history-aware RAG chain with Groq + AstraDB
```



## âš™ï¸ **Module Descriptions**

### **`config.py`**

Loads environment variables from the `.env` file and defines all key configuration values â€” including AstraDB credentials, Groq API keys, and model identifiers for embedding and generation.
This ensures all services (AstraDB, Hugging Face, Groq) remain securely and consistently accessible across the project.



### **`data_converter.py`**

Reads the Flipkart product review CSV file and converts each row into a **LangChain `Document`**.
Each document contains:

* **`page_content`** â€” the product review text
* **`metadata`** â€” the corresponding product title

This conversion step ensures uniform text objects suitable for embedding and vector search.



### **`data_ingestion.py`**

Initialises a **Hugging Face embedding model** and an **AstraDB Vector Store**.
It can:

* Return an existing AstraDB collection if available
* Or ingest all Flipkart reviews as new embedded documents for retrieval

This forms the persistent vector layer that powers semantic product recommendation.



### **`rag_chain.py`**

Builds a **history-aware Retrieval-Augmented Generation (RAG)** chain using **LangChain Core Runnable Expressions (LCEL)**.
It integrates:

* **Groq Chat Models** â€” for fast, contextually grounded responses
* **AstraDB Vector Store** â€” as a retriever for relevant product context
* **Message History** â€” to enable memory and conversational continuity

The `RAGChainBuilder` class rewrites user queries based on chat history, retrieves relevant review context, and generates accurate, concise responses.



## ğŸ§  **In Summary**

Together, these modules form the **core intelligence layer** of the LLMOps Flipkart Product Recommender:

* `config.py` â€” manages environment and model configuration.
* `data_converter.py` â€” transforms raw CSV data into structured documents.
* `data_ingestion.py` â€” builds and populates the AstraDB vector database.
* `rag_chain.py` â€” orchestrates retrieval-augmented reasoning using Groq and LangChain.

This backend foundation enables the next stages of the project â€” including **query handling**, **recommendation generation**, and **frontend integration** for an end-to-end intelligent product recommender system.
